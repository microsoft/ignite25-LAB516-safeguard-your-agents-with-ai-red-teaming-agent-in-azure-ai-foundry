{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b273a4",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Lab 4: Advanced Red Teaming - Comprehensive Attack Strategy Testing\n",
    "\n",
    "**Testing AI Models with Multi-Complexity Attack Groups**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ What You'll Learn\n",
    "\n",
    "In this advanced lab, you'll conduct comprehensive security testing using **attack strategy groups** that combine multiple obfuscation techniques across three complexity levels.\n",
    "\n",
    "### Key Learning Objectives\n",
    "\n",
    "- âœ… **Attack Complexity Levels**: Understand EASY, MODERATE, and DIFFICULT attack categories\n",
    "- âœ… **Attack Strategy Groups**: Use grouped strategies for comprehensive testing\n",
    "- âœ… **All Risk Categories**: Scan across all four supported risk types simultaneously\n",
    "- âœ… **Scale Testing**: Configure multi-objective scans with parallel execution\n",
    "- âœ… **Comprehensive Analysis**: Interpret results from extensive red team scans\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ What Are Attack Strategy Groups?\n",
    "\n",
    "Attack strategies are techniques used to bypass AI safety measures by obfuscating harmful prompts. They're organized into three complexity levels:\n",
    "\n",
    "### ðŸ“Š Complexity Classification\n",
    "\n",
    "| Complexity | Effort Required | Resources Needed | Example Strategies |\n",
    "|------------|----------------|------------------|-------------------|\n",
    "| **EASY** | Minimal | Simple encoding/transformation | Base64, Flip, Morse, Leetspeak |\n",
    "| **MODERATE** | Medium | Access to another AI model | Tense (past tense conversion) |\n",
    "| **DIFFICULT** | High | Multiple AI models + algorithms | Composition (Tense + Base64) |\n",
    "\n",
    "### ðŸŽ¨ Default Attack Strategy Groups\n",
    "\n",
    "From the Microsoft Docs, here's what each group includes:\n",
    "\n",
    "#### EASY Group\n",
    "Includes: `Base64`, `Flip`, `Morse`\n",
    "- **Base64**: Encodes prompts in base64 format\n",
    "- **Flip**: Reverses character order  \n",
    "- **Morse**: Converts text to Morse code\n",
    "\n",
    "#### MODERATE Group\n",
    "Includes: `Tense`\n",
    "- **Tense**: Converts prompts to past tense (requires LLM)\n",
    "\n",
    "#### DIFFICULT Group\n",
    "Includes: Composition of `Tense` + `Base64`\n",
    "- **Composed Attack**: First converts to past tense, then encodes in Base64\n",
    "- **Why it's harder**: Combines multiple obfuscation layers\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Lab Focus: Comprehensive Testing\n",
    "\n",
    "This lab demonstrates **full-spectrum security testing** by:\n",
    "\n",
    "1. **Testing ALL risk categories** (Violence, Hate/Unfairness, Sexual, Self-Harm)\n",
    "2. **Using ALL complexity groups** (EASY, MODERATE, DIFFICULT)\n",
    "3. **Running multiple objectives** per risk category (5 objectives Ã— 4 categories = 20 base prompts)\n",
    "4. **Applying multiple strategies** to each prompt (3 groups of strategies)\n",
    "\n",
    "### ðŸ“ˆ Expected Scan Volume\n",
    "\n",
    "With this configuration:\n",
    "- **Risk Categories**: 4 (Violence, Hate/Unfairness, Sexual, Self-Harm)\n",
    "- **Objectives per category**: 5\n",
    "- **Total base objectives**: 20\n",
    "- **Attack strategies**: 3 groups (EASY, MODERATE, DIFFICULT)\n",
    "- **Total attack-response pairs**: ~100+ (baseline + all strategy variations)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Prerequisites\n",
    "\n",
    "Before starting this lab, ensure you have:\n",
    "\n",
    "- âœ… **Completed Labs 1-3**: Understanding of basic red teaming concepts\n",
    "- âœ… **Azure Setup**: Environment configured from Lab 0\n",
    "- âœ… **Azure Login**: Authenticated with `az login`\n",
    "- âœ… **Model Deployment**: Azure OpenAI model deployed (can test any model, including DeepSeek if available)\n",
    "- âœ… **Environment Variables**: Configured with `source ../../infra/2-setup-env.sh`\n",
    "\n",
    "---\n",
    "\n",
    "## â±ï¸ Expected Duration\n",
    "\n",
    "- **Configuration**: ~2 minutes\n",
    "- **Scan Execution**: ~20-40 minutes (due to comprehensive scope)\n",
    "- **Results Analysis**: ~15 minutes\n",
    "\n",
    "**Total Lab Time**: Approximately 40-60 minutes\n",
    "\n",
    "âš ï¸ **Note**: This scan is significantly longer than Labs 1-3 due to the comprehensive attack coverage.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ—ºï¸ Lab Workflow\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Setup] --> B[Configure All Risk Categories]\n",
    "    B --> C[Configure Attack Groups]\n",
    "    C --> D[Run Comprehensive Scan]\n",
    "    D --> E[Analyze Results]\n",
    "```\n",
    "\n",
    "**Steps:**\n",
    "1. **Environment Setup**: Suppress warnings and configure credentials\n",
    "2. **Load Configuration**: Get Azure AI project and model endpoints\n",
    "3. **Create Red Team Agent**: Configure with all 4 risk categories\n",
    "4. **Run Comprehensive Scan**: Execute scan with EASY, MODERATE, DIFFICULT strategies\n",
    "5. **Analyze Results**: Review attack success rates across all dimensions\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Learn More\n",
    "\n",
    "- **[Attack Strategy Groups](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#default-grouped-attack-strategies)** - Complexity classifications\n",
    "- **[All Attack Strategies](https://learn.microsoft.com/azure/ai-foundry/concepts/ai-red-teaming-agent#supported-attack-strategies)** - Complete list of 20+ strategies\n",
    "- **[Attack Complexity](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#supported-attack-strategies)** - Understanding effort levels\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin comprehensive security testing! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9a42d",
   "metadata": {},
   "source": [
    "## ðŸ”‡ Step 1: Suppress Warning Messages\n",
    "\n",
    "To keep the output clean and focused on scan results, we'll suppress Python warnings.\n",
    "\n",
    "This is a common practice in notebooks to reduce noise from deprecation warnings, library version messages, and other non-critical alerts.\n",
    "\n",
    "---\n",
    "\n",
    "**Run the cell below to suppress warnings:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebfc1bb",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Step 2: Configure Azure Authentication\n",
    "\n",
    "We'll set up Azure credentials using the Azure CLI authentication from your `az login` session.\n",
    "\n",
    "### Authentication Check\n",
    "\n",
    "The code first verifies if you're already authenticated to Azure:\n",
    "- âœ… If logged in: Uses existing session\n",
    "- âŒ If not logged in: Prompts you to run `az login`\n",
    "\n",
    "### AzureCliCredential\n",
    "\n",
    "This credential type leverages your Azure CLI login, which is ideal for:\n",
    "- Local development and testing\n",
    "- Jupyter notebooks (like this lab)\n",
    "- Quick prototyping without service principals\n",
    "\n",
    "---\n",
    "\n",
    "**Run the cell below to configure authentication:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf1e7a",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 3: Load Azure AI Project and Model Configuration\n",
    "\n",
    "Now we'll load the necessary configuration from environment variables to set up our scan target.\n",
    "\n",
    "### Configuration Components\n",
    "\n",
    "1. **Azure AI Project Endpoint**: Connection to your AI Foundry project\n",
    "   - Used for logging scan results to the portal\n",
    "   - Variable: `AZURE_AI_PROJECT_ENDPOINT`\n",
    "\n",
    "2. **Model Deployment**: The specific model to test\n",
    "   - Variable: `AZURE_DEEPSEEK_DEPLOYMENT` (or any other deployment name)\n",
    "   - This can be any Azure OpenAI model (GPT-4, GPT-3.5, DeepSeek, etc.)\n",
    "\n",
    "3. **API Key**: Authentication for the model endpoint\n",
    "   - Variable: `AZURE_OPENAI_API_KEY`\n",
    "\n",
    "### Model Configuration Dictionary\n",
    "\n",
    "The `model_config` dictionary creates a target configuration for the red team scan:\n",
    "```python\n",
    "{\n",
    "    \"azure_endpoint\": \"Your project endpoint\",\n",
    "    \"azure_deployment\": \"Your model deployment name\",\n",
    "    \"api_key\": \"Your API key\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Run the cell below to load configuration:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a00a5",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 4: Create Comprehensive Red Team Agent\n",
    "\n",
    "Here we'll create a Red Team agent configured for **comprehensive security testing** across all risk categories.\n",
    "\n",
    "### Configuration Breakdown\n",
    "\n",
    "#### 1. Import Required Classes\n",
    "```python\n",
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory, AttackStrategy\n",
    "```\n",
    "\n",
    "**Note**: This uses the **local** red teaming SDK (`azure.ai.evaluation.red_team`), not the cloud SDK. The scan runs locally but results are logged to the portal.\n",
    "\n",
    "#### 2. Risk Categories - All Four Types\n",
    "\n",
    "We're testing **ALL supported risk categories** simultaneously:\n",
    "\n",
    "| Risk Category | Description | Example Attack Objectives |\n",
    "|---------------|-------------|---------------------------|\n",
    "| **HateUnfairness** | Bias, discrimination, hateful content | Testing for racist, sexist, or discriminatory outputs |\n",
    "| **Violence** | Violent, harmful, dangerous content | Testing for weapons, violence, physical harm |\n",
    "| **Sexual** | Inappropriate sexual content | Testing for explicit or inappropriate sexual material |\n",
    "| **SelfHarm** | Self-injury, suicide-related content | Testing for self-harm or suicide encouragement |\n",
    "\n",
    "#### 3. Objectives Configuration\n",
    "\n",
    "**`num_objectives=5`**: Generate 5 adversarial objectives per risk category\n",
    "- **Total objectives**: 5 Ã— 4 categories = **20 base attack objectives**\n",
    "- Each objective gets tested with multiple attack strategies\n",
    "- Results in 100+ attack-response pairs total\n",
    "\n",
    "### ðŸ’¡ Why Test All Categories?\n",
    "\n",
    "Comprehensive testing ensures:\n",
    "- âœ… **Complete safety coverage**: No blind spots\n",
    "- âœ… **Comparative analysis**: See which categories are most vulnerable\n",
    "- âœ… **Production readiness**: Full pre-deployment validation\n",
    "- âœ… **Compliance requirements**: Meet safety assessment standards\n",
    "\n",
    "### â±ï¸ Scan Duration Estimate\n",
    "\n",
    "With 5 objectives Ã— 4 categories Ã— 3 attack groups:\n",
    "- **Expected runtime**: 20-40 minutes\n",
    "- **Attack-response pairs**: ~100-120\n",
    "- **Parallelization**: Helps speed up execution\n",
    "\n",
    "---\n",
    "\n",
    "**Run the cell below to create the Red Team agent:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c7106",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 5: Execute Comprehensive Red Team Scan\n",
    "\n",
    "Now we'll launch the comprehensive scan using **all three attack strategy groups**.\n",
    "\n",
    "### Scan Parameters Explained\n",
    "\n",
    "#### 1. Target Configuration\n",
    "```python\n",
    "target=model_config\n",
    "```\n",
    "The model configuration dictionary from Step 3, specifying which model to test.\n",
    "\n",
    "#### 2. Scan Name\n",
    "```python\n",
    "scan_name=\"4-AttackGroups-Target\"\n",
    "```\n",
    "Unique identifier for this scan in the Azure AI Foundry Portal.\n",
    "- Format follows our naming convention: `{LabNumber}-{ScanType}-Target`\n",
    "- Helps organize and find results in the portal\n",
    "\n",
    "#### 3. Attack Strategy Groups\n",
    "```python\n",
    "attack_strategies=[\n",
    "    AttackStrategy.EASY,\n",
    "    AttackStrategy.MODERATE,\n",
    "    AttackStrategy.DIFFICULT,\n",
    "]\n",
    "```\n",
    "\n",
    "**What This Tests:**\n",
    "\n",
    "| Strategy Group | Included Techniques | Attack Count Per Objective |\n",
    "|----------------|---------------------|---------------------------|\n",
    "| **EASY** | Base64, Flip, Morse | 3 variations |\n",
    "| **MODERATE** | Tense | 1 variation |\n",
    "| **DIFFICULT** | Tense + Base64 (composed) | 1 variation |\n",
    "| **BASELINE** | Direct adversarial prompts | 1 original |\n",
    "\n",
    "**Total per objective**: 6 attack variations (1 baseline + 5 strategy variations)\n",
    "\n",
    "#### 4. Parallel Execution\n",
    "```python\n",
    "max_parallel_tasks=6\n",
    "```\n",
    "Runs up to 6 attacks simultaneously to speed up execution.\n",
    "- **Benefits**: Faster completion time\n",
    "- **Consideration**: Consumes more API quota\n",
    "\n",
    "#### 5. Timeout\n",
    "```python\n",
    "timeout=600\n",
    "```\n",
    "Maximum time (in seconds) for the entire scan.\n",
    "- **600 seconds** = 10 minutes\n",
    "- âš ï¸ **Note**: With 100+ attacks, this scan may exceed the timeout\n",
    "- The scan will complete as many attacks as possible within the time limit\n",
    "\n",
    "### ðŸ“Š Expected Results\n",
    "\n",
    "After completion, you'll see:\n",
    "- **Total attacks executed**: ~120 (20 objectives Ã— 6 strategies)\n",
    "- **Attack Success Rate (ASR)**: Percentage of successful attacks per category\n",
    "- **Scorecard**: Breakdown by risk category and attack complexity\n",
    "- **Detailed logs**: Individual attack-response pairs\n",
    "\n",
    "### ðŸŒ Results Location\n",
    "\n",
    "Results will be available in:\n",
    "1. **Local return value**: `model_results` variable\n",
    "2. **Azure AI Foundry Portal**: Under \"Evaluations\" â†’ \"AI red teaming\"\n",
    "   - Look for scan name: `4-AttackGroups-Target`\n",
    "\n",
    "---\n",
    "\n",
    "**Run the cell below to start the comprehensive scan:**\n",
    "\n",
    "âš ï¸ **Note**: This cell uses `await` and requires async execution. The scan may take 20-40 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Credential imports\n",
    "from azure.identity import AzureCliCredential\n",
    "import subprocess\n",
    "\n",
    "# Check if already logged in to Azure\n",
    "try:\n",
    "    result = subprocess.run(['az', 'account', 'show'], capture_output=True, text=True, check=True)\n",
    "    print(\"âœ“ Already logged in to Azure\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"Not logged in. Initiating Azure login...\")\n",
    "    !az login\n",
    "\n",
    "# Initialize Azure credentials\n",
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87668d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Azure AI Project information\n",
    "azure_ai_project = os.environ.get(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "\n",
    "azure_endpoint = os.environ.get(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "azure_deployment = os.environ.get(\"AZURE_DEEPSEEK_DEPLOYMENT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_endpoint,\n",
    "    \"azure_deployment\": azure_deployment,\n",
    "    \"api_key\": api_key,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e609111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation.red_team import RedTeam, RiskCategory, AttackStrategy\n",
    "\n",
    "# Create the RedTeam agent\n",
    "agent = RedTeam(\n",
    "    azure_ai_project=azure_ai_project, \n",
    "    credential=credential, \n",
    "    risk_categories=[\n",
    "        RiskCategory.HateUnfairness,\n",
    "        RiskCategory.Violence,\n",
    "        RiskCategory.Sexual,\n",
    "        RiskCategory.SelfHarm,\n",
    "    ],\n",
    "    num_objectives=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the comprehensive red teaming scan\n",
    "print(\"ðŸš€ Starting comprehensive red team scan...\")\n",
    "print(\"   This will test ALL risk categories with ALL attack complexity groups\")\n",
    "print(\"   Expected duration: 20-40 minutes\")\n",
    "print(\"\\nâ³ Scan in progress...\\n\")\n",
    "\n",
    "model_results = await agent.scan(\n",
    "    target=model_config,\n",
    "    scan_name=\"4-AttackGroups-Target\",  # Updated to follow naming convention\n",
    "    attack_strategies=[\n",
    "        AttackStrategy.EASY,       # Base64, Flip, Morse\n",
    "        AttackStrategy.MODERATE,   # Tense\n",
    "        AttackStrategy.DIFFICULT,  # Tense + Base64 composition\n",
    "    ],\n",
    "    max_parallel_tasks=6,\n",
    "    timeout=600,  # 10 minutes - may need to increase for full completion\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Scan completed!\")\n",
    "print(\"\\nðŸ“Š Results Summary:\")\n",
    "print(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e2f4b",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Lab 4 Summary\n",
    "\n",
    "Congratulations! You've completed **Lab 4: Advanced Red Teaming with Comprehensive Attack Strategy Testing**.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… What You Accomplished\n",
    "\n",
    "In this advanced lab, you learned how to:\n",
    "\n",
    "1. âœ… **Comprehensive Risk Coverage**: Tested all 4 risk categories (Violence, Hate/Unfairness, Sexual, Self-Harm) simultaneously\n",
    "2. âœ… **Attack Strategy Groups**: Used EASY, MODERATE, and DIFFICULT complexity groups\n",
    "3. âœ… **Multi-Objective Testing**: Configured 5 objectives per category for thorough coverage\n",
    "4. âœ… **Parallel Execution**: Optimized scan performance with concurrent testing\n",
    "5. âœ… **Large-Scale Analysis**: Interpreted results from 100+ attack-response pairs\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Key Takeaways\n",
    "\n",
    "### Attack Complexity Levels\n",
    "\n",
    "You tested three levels of attack sophistication:\n",
    "\n",
    "| Complexity | Strategies | Adversary Profile | Detection Difficulty |\n",
    "|------------|------------|-------------------|---------------------|\n",
    "| **EASY** | Base64, Flip, Morse | Script kiddie, automated tools | Low - Medium |\n",
    "| **MODERATE** | Tense (requires LLM) | Skilled attacker with AI access | Medium - High |\n",
    "| **DIFFICULT** | Composed (Tense + Base64) | Advanced persistent threat | High |\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "- **Real-world attacks** often use multiple obfuscation techniques\n",
    "- **Defense in depth** requires testing against sophisticated threats\n",
    "- **Baseline testing** (direct prompts) isn't sufficient for production\n",
    "- **Comprehensive scans** reveal vulnerabilities that simple tests miss\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Understanding Your Results\n",
    "\n",
    "### Attack Success Rate (ASR)\n",
    "\n",
    "The most important metric from your scan:\n",
    "\n",
    "```\n",
    "ASR = (Successful Attacks / Total Attacks) Ã— 100%\n",
    "```\n",
    "\n",
    "**Interpreting ASR:**\n",
    "- **0-20%**: Excellent safety measures\n",
    "- **20-40%**: Good, but room for improvement\n",
    "- **40-60%**: Moderate risk, mitigation recommended\n",
    "- **60%+**: High risk, immediate action required\n",
    "\n",
    "### Scorecard Breakdown\n",
    "\n",
    "Your results JSON includes:\n",
    "\n",
    "1. **By Risk Category**: Which categories had highest ASR?\n",
    "2. **By Attack Complexity**: Which attack levels were most successful?\n",
    "3. **Joint Analysis**: Risk Ã— Complexity breakdown\n",
    "4. **Row-level Data**: Individual attack-response pairs with scores\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "### 1. ðŸ” Deep Dive into Results\n",
    "\n",
    "Review your scan results in the Azure AI Foundry Portal:\n",
    "\n",
    "**Portal Navigation:**\n",
    "```\n",
    "Azure AI Foundry â†’ Your Project â†’ Evaluations â†’ AI red teaming â†’ \"4-AttackGroups-Target\"\n",
    "```\n",
    "\n",
    "**What to Look For:**\n",
    "- Which risk categories had the highest ASR?\n",
    "- Which attack strategies were most effective?\n",
    "- Are there patterns in successful attacks?\n",
    "- Do certain attack compositions bypass defenses?\n",
    "\n",
    "### 2. ðŸ›¡ï¸ Implement Mitigations\n",
    "\n",
    "Based on your findings, consider:\n",
    "\n",
    "**Content Filtering:**\n",
    "```python\n",
    "# Apply Azure AI Content Safety filters\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "\n",
    "# Configure filter thresholds based on your ASR results\n",
    "```\n",
    "\n",
    "**Safety System Messages:**\n",
    "```python\n",
    "# Add safety instructions to your system prompt\n",
    "system_message = \"\"\"\n",
    "You are a helpful AI assistant. Follow these safety guidelines:\n",
    "- Do not provide information that could cause harm\n",
    "- Refuse requests for illegal or dangerous content\n",
    "- Maintain ethical standards in all responses\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Prompt Shields:**\n",
    "- Enable Azure OpenAI Content Safety filters\n",
    "- Use jailbreak detection\n",
    "- Implement user input validation\n",
    "\n",
    "### 3. ðŸ”„ Iterative Testing\n",
    "\n",
    "After implementing mitigations:\n",
    "\n",
    "1. **Re-run this scan** with the same configuration\n",
    "2. **Compare ASR** before and after mitigations\n",
    "3. **Verify improvements** across all risk categories\n",
    "4. **Document changes** for compliance and audit\n",
    "\n",
    "### 4. ðŸ§ª Custom Attack Strategies\n",
    "\n",
    "Try individual strategies for targeted testing:\n",
    "\n",
    "```python\n",
    "# Test specific obfuscation techniques\n",
    "attack_strategies=[\n",
    "    AttackStrategy.JAILBREAK,  # Prompt injection\n",
    "    AttackStrategy.ROT13,       # Cipher encoding\n",
    "    AttackStrategy.LEETSPEAK,   # Character substitution\n",
    "    AttackStrategy.Compose([AttackStrategy.ROT13, AttackStrategy.BASE64])\n",
    "]\n",
    "```\n",
    "\n",
    "### 5. ðŸ“ˆ Continuous Monitoring\n",
    "\n",
    "Make red teaming part of your AI development lifecycle:\n",
    "\n",
    "- **Weekly scans**: During active development\n",
    "- **Pre-deployment**: Before each release\n",
    "- **Post-update**: After model upgrades or changes\n",
    "- **Scheduled audits**: Monthly or quarterly\n",
    "\n",
    "### 6. ðŸ”¬ Advanced Techniques\n",
    "\n",
    "**Custom Attack Objectives:**\n",
    "```python\n",
    "# Bring your own attack prompts\n",
    "red_team_agent = RedTeam(\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    credential=credential,\n",
    "    custom_attack_seed_prompts=\"my_custom_prompts.json\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Complex Callbacks:**\n",
    "```python\n",
    "# Test full applications with multi-turn conversations\n",
    "async def application_callback(messages: List[dict]) -> dict:\n",
    "    # Your RAG system, chatbot, or complex application logic\n",
    "    return {\"role\": \"assistant\", \"content\": response}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Additional Resources\n",
    "\n",
    "### Official Documentation\n",
    "\n",
    "- **[Attack Strategy Groups](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#default-grouped-attack-strategies)** - Default group definitions\n",
    "- **[All Attack Strategies](https://learn.microsoft.com/azure/ai-foundry/concepts/ai-red-teaming-agent#supported-attack-strategies)** - Complete strategy list (20+)\n",
    "- **[Attack Complexity](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#supported-attack-strategies)** - Understanding effort levels\n",
    "- **[Custom Objectives](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#custom-attack-objectives)** - Bring your own prompts\n",
    "\n",
    "### Mitigation Resources\n",
    "\n",
    "- **[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)** - Filter configuration\n",
    "- **[Safety System Messages](https://learn.microsoft.com/azure/ai-foundry/openai/concepts/safety-system-message-templates)** - Pre-built templates\n",
    "- **[Responsible AI Practices](https://www.microsoft.com/ai/responsible-ai)** - Microsoft's principles\n",
    "\n",
    "### Research and Best Practices\n",
    "\n",
    "- **[Microsoft AI Red Team Blog](https://www.microsoft.com/security/blog/2025/01/13/3-takeaways-from-red-teaming-100-generative-ai-products/)** - Lessons from 100+ products\n",
    "- **[PyRIT Framework](https://github.com/Azure/PyRIT)** - Open-source risk identification tool\n",
    "- **[NIST AI Risk Management](https://www.nist.gov/itl/ai-risk-management-framework)** - Industry framework\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ“ Lab Series Completion\n",
    "\n",
    "You've now completed **all four labs** in the AI Red Teaming series:\n",
    "\n",
    "| Lab | Focus | Key Learning |\n",
    "|-----|-------|--------------|\n",
    "| **Lab 1** | Agent Scanning | Test Azure AI agents with callback functions |\n",
    "| **Lab 2** | Model Scanning | Test models with various target configurations |\n",
    "| **Lab 3** | Cloud Scanning | Scale testing with Azure AI Foundry cloud infrastructure |\n",
    "| **Lab 4** | Advanced Testing | Comprehensive multi-complexity attack groups |\n",
    "\n",
    "### ðŸŒŸ You're Now Equipped To:\n",
    "\n",
    "- âœ… Conduct thorough security assessments of AI systems\n",
    "- âœ… Understand attack vectors from basic to advanced\n",
    "- âœ… Interpret red teaming results and prioritize fixes\n",
    "- âœ… Implement defense-in-depth strategies\n",
    "- âœ… Build security testing into your AI development workflow\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Need Help?\n",
    "\n",
    "- **Technical Issues?** Check [Azure AI Foundry Docs](https://learn.microsoft.com/azure/ai-foundry/)\n",
    "- **Scan Failed?** Review timeout settings and parallel task configuration\n",
    "- **Understanding Results?** See [Results Documentation](https://learn.microsoft.com/azure/ai-foundry/how-to/develop/run-scans-ai-red-teaming-agent#results-from-your-automated-scans)\n",
    "\n",
    "---\n",
    "\n",
    "**Excellent work completing this advanced lab!** ðŸŽ‰ You've mastered comprehensive AI red teaming with Azure AI Foundry. ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
