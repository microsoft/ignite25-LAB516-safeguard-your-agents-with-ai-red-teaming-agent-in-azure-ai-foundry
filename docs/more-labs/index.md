# More Labs

These "bonus" labs build upon the foundational knowledge from Labs 0-3 and will capture advanced usage scenarios or dive deeper into key features with more nuanced exercises. _They are meant to be completed at home, or if time permits in venue AFTER you complete the core labs_.

### Prerequisites

!!! info "Before starting these bonus labs, you should have:"

    - [X] Completed Labs 0-3 (core labs)
    - [X] Understanding of basic red teaming concepts
    - [X] Familiarity with Azure AI Foundry SDK
    - [X] Active Azure AI Foundry project

---

## Lab 4: Red Teaming Cora


**Duration:** 45-60 minutes 

Test a production-ready AI shopping assistant with real product data for safety vulnerabilities using baseline and advanced attack strategies.


**What You'll Do**

- Create Azure AI Agents with file search capabilities
- Run baseline red teaming scans with direct attacks
- Apply advanced attack strategies (Base64, ROT13, Leetspeak, Composition)
- Analyze Attack Success Rate (ASR) by risk category
- Interpret results and identify vulnerabilities
- Apply production AI safety best practices

[Start Lab 4 â†’](04-scan-advanced.md){ .md-button .md-button--primary }

---

## Future Labs

We will continue to add labs to this section to track the latest feature updates to the Azure AI Red Teaming agent, and provide more hands-on guidance for real-world usage. This can include topics like:

- **Custom Attack Strategies**: Build your own attack strategy plugins
- **Multi-Turn Conversations**: Test complex conversation flows
- **Specialized Scenarios**: Domain-specific security testing
- **Integration Testing**: Red teaming in CI/CD pipelines

---

[Back to Core Labs](../core-labs/index.md){ .md-button }
